{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a038d1",
   "metadata": {},
   "source": [
    "#### Forward propagation\n",
    "\n",
    "It is the process of computing the output of a neural network given a set of input data. It involves propagating the input data through the network, computing the output at each layer using the current weights, and finally outputting the prediction made by the network. \n",
    "\n",
    "This step is called forward propagation because the data is propagated forward through the network from the input layer to the output layer. During forward propagation, the input data is multiplied by the weights at each layer, and then passed through an activation function to produce the output.\n",
    "\n",
    "#### Backward propagation\n",
    "\n",
    "It is the process of updating the weights in a neural network so that the network can make better predictions on the training data. It involves computing the gradient of the loss function with respect to the weights at each layer, and then updating the weights using a gradient descent optimization algorithm. \n",
    "\n",
    "This step is called backward propagation because the gradient is propagated backward through the network from the output layer to the input layer. During backward propagation, the gradient of the loss function with respect to the output is first computed, and then the gradient is propagated backward through the layers of the network using the chain rule of differentiation to compute the gradients with respect to the weights at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05300448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455f060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output data for the AND gate\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [0], [0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053b7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5719cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class AND:\n",
    "    def __init__(self):\n",
    "        self.input_layer_size = 2\n",
    "        self.hidden_layer_size = 2\n",
    "        self.output_layer_size = 1\n",
    "\n",
    "        # Initialize the weights for the hidden layer and output layer\n",
    "        self.weights_hidden = np.random.randn(self.input_layer_size, self.hidden_layer_size)\n",
    "        self.weights_output = np.random.randn(self.hidden_layer_size, self.output_layer_size)\n",
    "        \n",
    "        # Initialize the bias terms for the hidden layer and output layer\n",
    "        self.bias_hidden = np.array([0,0])\n",
    "        self.bias_output = np.array([-0.5])\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Propagate inputs through the neural network\n",
    "        self.hidden_layer = sigmoid(np.dot(X, self.weights_hidden)+ self.bias_hidden) \n",
    "        self.output_layer = sigmoid(np.dot(self.hidden_layer, self.weights_output)+ self.bias_output)\n",
    "        return self.output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb71d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25088733]\n",
      " [0.13829876]\n",
      " [0.30520961]\n",
      " [0.15602996]]\n"
     ]
    }
   ],
   "source": [
    "# Create a neural network instance\n",
    "nn = AND()\n",
    "\n",
    "# Compute the output data for the AND gate using forward propagation\n",
    "output_data = nn.forward(X)\n",
    "\n",
    "# Print the output data\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6a1645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0017125 ]\n",
      " [0.01095283]\n",
      " [0.01050146]\n",
      " [0.37712398]]\n"
     ]
    }
   ],
   "source": [
    "# Create a neural network instance and train it on the input and output data\n",
    "# Using Backward Propagation\n",
    "nn = AND()\n",
    "for i in range(10000):\n",
    "    nn.forward(X)\n",
    "    error = y - nn.output_layer\n",
    "    delta_output = error * nn.output_layer * (1 - nn.output_layer)\n",
    "    delta_hidden = np.dot(delta_output, nn.weights_output.T) * nn.hidden_layer * (1 - nn.hidden_layer)\n",
    "    nn.weights_output += np.dot(nn.hidden_layer.T, delta_output)\n",
    "    nn.weights_hidden += np.dot(X.T, delta_hidden)\n",
    "\n",
    "# Test the neural network on the input data\n",
    "print(nn.forward(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b26055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
